{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from google.oauth2 import service_account\n",
    "from google.cloud import vision\n",
    "from google.cloud import storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the key from the environment variable\n",
    "service_account_key =os.getenv('GCP_ACCESS_KEY')\n",
    "if not service_account_key:\n",
    "    raise ValueError(\"The GCP_SERVICE_ACCOUNT_KEY environment variable is not set\")\n",
    "\n",
    "key_data = json.loads(service_account_key)\n",
    "\n",
    "credentials = service_account.Credentials.from_service_account_info(\n",
    "    key_data,\n",
    "    scopes=[\"https://www.googleapis.com/auth/cloud-platform\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_acc_key=os.getenv('GCP_ACCESS_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_id = os.getenv('GOOGLE_PROJECT_MAIN_FP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def async_detect_document(gcs_source_uri, gcs_destination_uri):\n",
    "\n",
    "    \"\"\"OCR with PDF/TIFF as source files on GCS\"\"\"\n",
    "    import json\n",
    "    import re\n",
    "    from google.cloud import vision\n",
    "    from google.cloud import storage\n",
    "\n",
    "    # Supported mime_types are: 'application/pdf' and 'image/tiff'\n",
    "    mime_type = \"application/pdf\"\n",
    "\n",
    "    # How many pages should be grouped into each json output file.\n",
    "    batch_size = 2\n",
    "\n",
    "    client = vision.ImageAnnotatorClient(credentials=credentials)\n",
    "\n",
    "    feature = vision.Feature(type_=vision.Feature.Type.DOCUMENT_TEXT_DETECTION)\n",
    "\n",
    "    gcs_source = vision.GcsSource(uri=gcs_source_uri)\n",
    "    input_config = vision.InputConfig(gcs_source=gcs_source, mime_type=mime_type)\n",
    "\n",
    "    gcs_destination = vision.GcsDestination(uri=gcs_destination_uri)\n",
    "    output_config = vision.OutputConfig(\n",
    "        gcs_destination=gcs_destination, batch_size=batch_size\n",
    "    )\n",
    "\n",
    "    async_request = vision.AsyncAnnotateFileRequest(\n",
    "        features=[feature], input_config=input_config, output_config=output_config\n",
    "    )\n",
    "\n",
    "    operation = client.async_batch_annotate_files(requests=[async_request])\n",
    "\n",
    "    print(\"Waiting for the operation to finish.\")\n",
    "    operation.result(timeout=420)\n",
    "\n",
    "    # Once the request has completed and the output has been\n",
    "    # written to GCS, we can list all the output files.\n",
    "    storage_client = storage.Client(credentials=credentials)\n",
    "\n",
    "    match = re.match(r\"gs://([^/]+)/(.+)\", gcs_destination_uri)\n",
    "    bucket_name = match.group(1)\n",
    "    prefix = match.group(2)\n",
    "\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "    # List objects with the given prefix, filtering out folders.\n",
    "    blob_list = [\n",
    "        blob\n",
    "        for blob in list(bucket.list_blobs(prefix=prefix))\n",
    "        if not blob.name.endswith(\"/\")\n",
    "    ]\n",
    "    print(\"Output files:\")\n",
    "    for blob in blob_list:\n",
    "        print(blob.name)\n",
    "\n",
    "    # Process the first output file from GCS.\n",
    "    # Since we specified batch_size=2, the first response contains\n",
    "    # the first two pages of the input file.\n",
    "    output = blob_list[0]\n",
    "\n",
    "    json_string = output.download_as_bytes().decode(\"utf-8\")\n",
    "    response = json.loads(json_string)\n",
    "\n",
    "    # The actual response for the first page of the input file.\n",
    "    first_page_response = response[\"responses\"][0]\n",
    "    annotation = first_page_response[\"fullTextAnnotation\"]\n",
    "\n",
    "    # Here we print the full text from the first page.\n",
    "    # The response contains more information:\n",
    "    # annotation/pages/blocks/paragraphs/words/symbols\n",
    "    # including confidence scores and bounding boxes\n",
    "    print(\"Full text:\\n\")\n",
    "    print(annotation[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#async_detect_document('gs://dataset_samples/sample_pdf/chat_gpt_bill_check.pdf', 'gs://dataset_samples/sample_pdf/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
